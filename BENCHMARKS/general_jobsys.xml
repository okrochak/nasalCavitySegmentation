<?xml version="1.0" encoding="UTF-8"?>
<!-- author: EI -->
<!-- version: 221005a -->

<jube>
  <benchmark name="bench" outpath="bench_run">
    <comment>General benchmark script</comment>
   
    <!-- bench configuration -->
    <parameterset name="paramset">
      <!-- iterated nodes -->
      <parameter name="iterNO" type="int">1</parameter>
      <!-- iterated batch_sizes -->
      <parameter name="iterBS" type="int">3</parameter>
      <!-- iterated epochs -->
      <parameter name="iterEP" type="int">1</parameter>
      <!-- iterated learning rates -->
      <parameter name="iterLR" type="float">0.01</parameter>
      <!-- iterated #workers -->
      <parameter name="iterNW" type="int">32</parameter>
      <!-- iterated prefetch factor -->
      <parameter name="iterPF" type="int">2</parameter>
      <!-- modify the name of the job script -->
      <parameter name="script">pytorch.py</parameter>
    </parameterset>
    
    <!-- job configuration -->
    <parameterset name="executeset">
      <parameter name="systemname" mode="shell">if [ -f /etc/FZJ/systemname ]; then cat /etc/FZJ/systemname | tr -d "\n"; else uname -n | head -c 3; fi</parameter>
      <parameter name="submit_cmd">sbatch</parameter>
      <parameter name="nodes">$iterNO</parameter>
      <parameter name="nbs">$iterBS</parameter>
      <parameter name="nes">$iterEP</parameter>
      <parameter name="nlr">$iterLR</parameter>
      <parameter name="nnw">$iterNW</parameter>
      <parameter name="npf">$iterPF</parameter>
      <parameter name="ready_file">ready</parameter>
      <parameter name="job_file">benchScript.sh</parameter>
      <parameter name="ngpu" mode="python" type="int">
        { "juwelsbooster": 4,
          "jurecadc": 4,
          "deep": 1,
          "amd": 2,
        }["${systemname}"]
      </parameter>
      <parameter name="nlr_m" mode="python" type="float">
        ${nodes}*${nlr}*${ngpu}
      </parameter>      
      <parameter name="gres" separator="!" mode="python">
        {
          "juwelsbooster": "gpu:4",
          "jurecadc": "gpu:4",
          "deep": "",
          "amd": "gpu:2",
        }["${systemname}"]
      </parameter>
      <parameter name="account" mode="python">
        { "juwelsbooster": "slfse",
          "jurecadc": "raise-ctp1",
          "deep": "deepext",
          "amd": "bsc_case",
        }["${systemname}"]
      </parameter>
      <parameter name="datadir" mode="python">
        { "juwelsbooster": "/p/project/prcoe12/RAISE/T31_LD/",
          "jurecadc": "/p/scratch/raise-ctp1/inanc2/T31_LD/",
          "deep": "/p/project/prcoe12/RAISE/T31_LD/",
          "amd": "/gpfs/scratch/bsc21/bsc21163/RAISE_Dataset/T31/", 
        }["${systemname}"]
      </parameter>

      <!-- main run -->
      <parameter name="timelimit" tag="!devel">24:00:00</parameter>
      <parameter name="queue" tag="!devel" mode="python">
        { "juwelsbooster": "booster",
          "jurecadc": "dc-gpu",
          "deep": "ib-esb",
          "amd": "bsc_case",
        }["${systemname}"]
      </parameter>
      <!-- devel run -->
      <parameter name="timelimit" tag="devel">02:00:00</parameter>
      <parameter name="queue" tag="devel" mode="python">
        { "juwelsbooster": "develbooster",
          "jurecadc": "dc-gpu-devel",
          "deep": "ib-esb",
          "amd": "bsc_case",
        }["${systemname}"]
      </parameter>
    </parameterset>

    <parameterset name="envirset">
      <parameter name="load_modules" separator="!" mode="python">  {
          "juwelsbooster": "ml Stages/2022 GCC OpenMPI cuDNN NCCL Python libaio", 
          "jurecadc": "ml Stages/2022 NVHPC ParaStationMPI/5.5.0-1-mt Python CMake NCCL cuDNN libaio HDF5 PnetCDF mpi-settings/CUDA", 
          "deep": "ml --force purge; ml use $OTHERSTAGES; ml Stages/2022 GCC OpenMPI cuDNN NCCL Python",
          "amd": "ml gcc openmpi rocm python", 
        }["${systemname}"]
      </parameter>
      <parameter name="python_env" separator="!" mode="python">{
          "juwelsbooster" : "source /p/project/prcoe12/RAISE/envAI_juwels/bin/activate", 
          "jurecadc": "source /p/project/raise-ctp1/RAISE/envAI_jureca/bin/activate", 
          "deep": "source /p/project/prcoe12/RAISE/envAI_deepv/bin/activate", 
          "amd": "source /gpfs/projects/bsc21/bsc21163/envAI_BSC/bin/activate; export LD_LIBRARY_PATH=/gpfs/projects/bsc21/bsc21163/envAI_BSC/lib:$LD_LIBRARY_PATH" 
      }["${systemname}"]
      </parameter>
      <parameter name="devices" separator="!" mode="python">{
          "juwelsbooster" : "export CUDA_VISIBLE_DEVICES=0,1,2,3",
          "jurecadc": "export CUDA_VISIBLE_DEVICES=0,1,2,3",
          "deep": "export CUDA_VISIBLE_DEVICES=0",
          "amd": "export MIOPEN_DEBUG_DISABLE_FIND_DB=1" 
      }["${systemname}"]
      </parameter>
    </parameterset>

    <!-- load jobfile -->
    <fileset name="files">
      <copy>$job_file</copy>
      <link>$script</link>
    </fileset>

    <!-- substitute jobfile -->
    <substituteset name="sub_job">
      <iofile in="${job_file}" out="$job_file" />
      <sub source="#NODES#" dest="$nodes" />
      <sub source="#BS#" dest="$nbs" />
      <sub source="#EPCS#" dest="$nes" />
      <sub source="#LR#" dest="$nlr" />
      <sub source="#READY#" dest="$ready_file" />
      <sub source="#LRM#" dest="$nlr_m" />
      <sub source="#NW#" dest="$nnw" />
      <sub source="#PF#" dest="$npf" />
      <sub source="#SCRIPT#" dest="$script" />
      <sub source="#ACC#" dest="$account" />
      <sub source="#NGPU#" dest="$ngpu" />
      <sub source="#GRES#" dest="$gres" />
      <sub source="#TIMELIM#" dest="$timelimit" />
      <sub source="#QUEUE#" dest="$queue" />
      <sub source="#DATADIR#" dest="$datadir" />
      <sub source="#MODULES#" dest="$load_modules" />
      <sub source="#ENVS#" dest="$python_env" />
      <sub source="#DEVICES#" dest="$devices" />
    </substituteset> 

    <!-- operation/execution of bench -->
    <step name="submit" work_dir="JUBE/${jube_benchmark_id}_${jube_wp_id}" >
      <use>paramset</use>
      <use>executeset</use>
      <use>envirset</use>
      <use>files,sub_job</use>
      <do>echo "nID: $jube_wp_id"</do> <!-- shell command -->

      <do done_file="$ready_file">$submit_cmd $job_file</do> <!-- shell command -->
    </step>

    <!-- results -->
    <!-- regex pattern -->
    <patternset name="pattern">
      <pattern name="ID" unit="" type="int">\s*nID:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="Nnodes" unit="" type="int">\s*DEBUG: SLURM_NNODES:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="Nworkers" unit="" type="int">\s*DEBUG: args.nworker:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="prefetchF" unit="" type="int">\s*DEBUG: args.prefetch:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="batchSize" unit="" type="int">\s*DEBUG: args.batch_size:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="Nepochs" unit="" type="int">\s*DEBUG: args.epochs:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="learningRate" unit="" type="float">\s*DEBUG: args.lr:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="calcTime" unit="s" type="float">\s*TIMER: total epoch time:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="lastEpochT" unit="s" type="float">\s*TIMER: last epoch time:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="memoryGPU" unit="MB" type="int">\s*DEBUG: memory req:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="avgTestLoss" unit="" type="float">\s*DEBUG: avg_test_loss:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="avgMeanDiff" unit="" type="float">\s*DEBUG: avg_mean_sqr_diff:\s+$jube_pat_wrd\s*</pattern>
    </patternset>

    <!-- analyse -->
    <analyzer name="analyse" >
      <use>pattern</use> <!-- use existing patternset -->
      <analyse step="submit">
        <file>stdout</file>
        <file>job.out</file>
      </analyse>
    </analyzer>

    <!-- create result table -->
    <result>
      <use>analyse</use>
      <table name="result" style="pretty" sort="jube_wp_id">
        <column>ID</column>
        <column>Nnodes</column>
        <column>Nworkers</column>
        <column>prefetchF</column>
        <column>batchSize</column>
        <column>Nepochs</column>
        <column>learningRate</column>
        <column>calcTime</column>
        <column>lastEpochT</column>
        <column>memoryGPU</column>
        <column>avgTestLoss</column>
        <column>avgMeanDiff</column>
      </table>
    </result>
    
  </benchmark>
</jube>

<!-- eof -->
