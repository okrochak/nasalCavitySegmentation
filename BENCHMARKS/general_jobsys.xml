<?xml version="1.0" encoding="UTF-8"?>
<!-- author: EI -->
<!-- version: 220526a -->

<jube>
  <benchmark name="bench" outpath="bench_run">
    <comment>General benchmark script</comment>

    <!-- bench configuration -->
    <parameterset name="paramset">
      <!-- iterated nodes -->
      <parameter name="iterNO" type="int">1,2,4,8,16,24</parameter>
      <!-- iterated batch_sizes -->
      <parameter name="iterBS" type="int">1</parameter>
      <!-- iterated epochs -->
      <parameter name="iterEP" type="int">10</parameter>
      <!-- iterated learning rates -->
      <parameter name="iterLR" type="float">0.0001</parameter>
      <!-- iterated #workers -->
      <parameter name="iterNW" type="int">32</parameter>
      <!-- iterated prefetch factor -->
      <parameter name="iterPF" type="int">2</parameter>
      <!-- modify the name of the job script -->
      <parameter name="script">DDP_pytorch_AT_LD_DM.py</parameter>
    </parameterset>

    <!-- job configuration -->
    <parameterset name="executeset">
      <parameter name="systemname" mode="shell">if [ -f /etc/FZJ/systemname ]; then cat /etc/FZJ/systemname | tr -d "\n"; else uname -n | head -c 3; fi</parameter>
      <parameter name="submit_cmd">sbatch</parameter>
      <parameter name="nodes">$iterNO</parameter>
      <parameter name="nbs">$iterBS</parameter>
      <parameter name="nes">$iterEP</parameter>
      <parameter name="nlr">$iterLR</parameter>
      <parameter name="nnw">$iterNW</parameter>
      <parameter name="npf">$iterPF</parameter>
      <parameter name="ready_file">ready</parameter>
      <parameter name="job_file">benchScript.sh</parameter>
      <parameter name="ngpu" mode="python" type="int">
        { "juwelsbooster": 4,
          "jurecadc": 4,
          "deep": 1,
          "amd": 2,
        }["${systemname}"]
      </parameter>
      <parameter name="nlr_m" mode="python" type="float">${nodes}*${nlr}*${ngpu}</parameter>
      <parameter name="gres" separator="!" mode="python">
        { "juwelsbooster": "gpu:4",
          "jurecadc": "gpu:4",
          "deep": "",
          "amd": "gpu:2",
        }["${systemname}"]
      </parameter>
      <parameter name="account" mode="python">
        { "juwelsbooster": "slfse",
          "jurecadc": "raise-ctp2",
          "deep": "deepext",
          "amd": "bsc_case",
        }["${systemname}"]
      </parameter>
      <parameter name="datadir" mode="python">
        { "juwelsbooster": "/p/scratch/raise-ctp2/inanc2/T31_LD/",
          "jurecadc": "/p/scratch/raise-ctp2/inanc2/T31_LD/",
          "deep": "/p/project/prcoe12/RAISE/T31_LD/",
          "amd": "/gpfs/scratch/bsc21/bsc21163/RAISE_Dataset/T31/",
        }["${systemname}"]
      </parameter>

      <!-- main run -->
      <parameter name="timelimit" tag="!devel">00:30:00</parameter>
      <parameter name="queue" tag="!devel" mode="python">
        { "juwelsbooster": "booster",
          "jurecadc": "dc-gpu",
          "deep": "dp-esb",
          "amd": "bsc_case",
        }["${systemname}"]
      </parameter>
      <!-- devel run -->
      <parameter name="timelimit" tag="devel">00:10:00</parameter>
      <parameter name="queue" tag="devel" mode="python">
        { "juwelsbooster": "develbooster",
          "jurecadc": "dc-gpu-devel",
          "deep": "dp-esb",
          "amd": "bsc_case",
        }["${systemname}"]
      </parameter>
    </parameterset>

    <parameterset name="envirset">
      <parameter name="load_modules" separator="!" mode="python">  {
          "juwelsbooster": "ml --force purge; ml Stages/2023 StdEnv/2023 NVHPC/23.1 OpenMPI/4.1.4 cuDNN/8.6.0.163-CUDA-11.7 Python/3.10.4 HDF5 libaio",
          "jurecadc": "ml --force purge; ml Stages/2022 NVHPC/22.3 ParaStationMPI/5.5.0-1-mt Python NCCL/2.12.7-1-CUDA-11.5 cuDNN libaio HDF5 mpi-settings/CUDA",
          "deep": "ml --force purge; ml use $OTHERSTAGES; ml Stages/2022 GCC OpenMPI cuDNN NCCL Python",
          "amd": "ml gcc openmpi rocm python",
        }["${systemname}"]
      </parameter>
      <parameter name="python_env" separator="!" mode="python">{
          "juwelsbooster" : "source /p/project/prcoe12/RAISE/envAI_juwels/bin/activate",
          "jurecadc": "source /p/project/prcoe12/RAISE/envAI_jureca/bin/activate",
          "deep": "source /p/project/prcoe12/RAISE/envAI_deepv/bin/activate",
          "amd": "source /gpfs/projects/bsc21/bsc21163/envAI_BSC/bin/activate; export LD_LIBRARY_PATH=/gpfs/projects/bsc21/bsc21163/envAI_BSC/lib:$LD_LIBRARY_PATH"
      }["${systemname}"]
      </parameter>
      <parameter name="devices" separator="!" mode="python">{
          "juwelsbooster" : "export CUDA_VISIBLE_DEVICES=0,1,2,3",
          "jurecadc": "export CUDA_VISIBLE_DEVICES=0,1,2,3",
          "deep": "export CUDA_VISIBLE_DEVICES=0",
          "amd": "export MIOPEN_INFO_DISABLE_FIND_DB=1"
      }["${systemname}"]
      </parameter>
    </parameterset>

    <!-- load jobfile -->
    <fileset name="files">
      <copy>$job_file</copy>
      <link>$script</link>
    </fileset>

    <!-- substitute jobfile -->
    <substituteset name="sub_job">
      <iofile in="${job_file}" out="$job_file" />
      <sub source="#NODES#" dest="$nodes" />
      <sub source="#BS#" dest="$nbs" />
      <sub source="#EPCS#" dest="$nes" />
      <sub source="#LR#" dest="$nlr" />
      <sub source="#READY#" dest="$ready_file" />
      <sub source="#LRM#" dest="$nlr_m" />
      <sub source="#NW#" dest="$nnw" />
      <sub source="#PF#" dest="$npf" />
      <sub source="#SCRIPT#" dest="$script" />
      <sub source="#ACC#" dest="$account" />
      <sub source="#NGPU#" dest="$ngpu" />
      <sub source="#GRES#" dest="$gres" />
      <sub source="#TIMELIM#" dest="$timelimit" />
      <sub source="#QUEUE#" dest="$queue" />
      <sub source="#DATADIR#" dest="$datadir" />
      <sub source="#MODULES#" dest="$load_modules" />
      <sub source="#ENVS#" dest="$python_env" />
      <sub source="#DEVICES#" dest="$devices" />
    </substituteset>

    <!-- operation/execution of bench -->
    <step name="submit" work_dir="JUBE/${jube_benchmark_id}_${jube_wp_id}" >
      <use>paramset</use>
      <use>executeset</use>
      <use>envirset</use>
      <use>files,sub_job</use>
      <do>echo "nID: $jube_wp_id"</do> <!-- shell command -->

      <do done_file="$ready_file">$submit_cmd $job_file</do> <!-- shell command -->
    </step>

   <!-- results -->
    <!-- regex pattern -->
    <patternset name="pattern">
      <pattern name="ID" type="int">${jube_wp_id}</pattern>
      <pattern name="Nnodes" type="int">${nodes}</pattern>
      <pattern name="Nworkers" type="int">${nnw}</pattern>
      <pattern name="prefetchF" type="int">${npf}</pattern>
      <pattern name="batchSize" type="int">${nbs}</pattern>
      <pattern name="Nepochs" type="int">${nes}</pattern>
      <pattern name="learningRate" type="float">${nlr}</pattern>
      <pattern name="calcTime" unit="s" type="float">\s*INFO: total epoch-2 time:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="avgEpochT" unit="s" type="float">\s*INFO: average epoch-2 time:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="Naet" unit="s" type="float" mode="python">${avgEpochT}/${nodes}</pattern>
      <pattern name="memory" unit="MB" type="int">\s*INFO: memory req:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="memoryGPU" unit="GB" type="float" mode="python">${memory}/1024</pattern>
      <pattern name="avgTestLoss" unit="" type="float">\s*INFO: avg_test_loss:\s+$jube_pat_wrd\s*</pattern>
      <pattern name="avgMeanDiff" unit="" type="float">\s*INFO: avg_mean_sqr_diff:\s+$jube_pat_wrd\s*</pattern>
    </patternset>

    <!-- analyse -->
    <analyzer name="analyse" >
      <use>pattern</use> <!-- use existing patternset -->
      <analyse step="submit">
        <file>stdout</file>
        <file>job.out</file>
      </analyse>
    </analyzer>

    <!-- create result table in CSV-->
    <result result_dir="results">
      <use>analyse</use>
      <table name="result-csv" style="csv" sort="jube_wp_id">
        <column>ID</column>
        <column>Nnodes</column>
        <column>Nworkers</column>
        <column>prefetchF</column>
        <column>batchSize</column>
        <column>Nepochs</column>
        <column>learningRate</column>
        <column format=".3f">calcTime</column>
        <column format=".3f">avgEpochT</column>
        <column format=".3f">Naet</column>
        <column format=".1f">memoryGPU</column>
        <column format=".10f">avgTestLoss</column>
        <column format=".3f">avgMeanDiff</column>
      </table>
    </result>

    <!-- create result table -->
    <result>
      <use>analyse</use>
      <table name="result" style="pretty" sort="jube_wp_id">
        <column>ID</column>
        <column>Nnodes</column>
        <column>Nworkers</column>
        <column>prefetchF</column>
        <column>batchSize</column>
        <column>Nepochs</column>
        <column>learningRate</column>
        <column format=".3f">calcTime</column>
        <column format=".3f">avgEpochT</column>
        <column format=".3f">Naet</column>
        <column format=".1f">memoryGPU</column>
        <column format=".10f">avgTestLoss</column>
        <column format=".3f">avgMeanDiff</column>
      </table>
    </result>

  </benchmark>
</jube>

<!-- eof -->
